{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eea6e90",
   "metadata": {},
   "source": [
    "# 00 - Importação de Bilbiotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef5f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import os \n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d96b67",
   "metadata": {},
   "source": [
    "# 01 - Etapa de Descompactação dos Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29bc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas0.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas1.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas2.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas3.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas4.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas5.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas6.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas7.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas8.zip\n",
      "C:\\Temp\\Iesus\\dados\\arquivo_zip\\Empresas9.zip\n"
     ]
    }
   ],
   "source": [
    "unzip_file_path = fr\"C:\\Temp\\Iesus\\dados\\arquivo_csv\"\n",
    "\n",
    "zip_file_path =  fr\"C:\\Temp\\Iesus\\dados\\arquivo_zip\"\n",
    "\n",
    "file_list = os.listdir(zip_file_path)\n",
    "\n",
    "for file in file_list:\n",
    "    \n",
    "    if file.endswith('.zip'):\n",
    "        \n",
    "        x = zip_file_path + '\\\\' + file\n",
    "        print (x)\n",
    "        zip = zipfile.ZipFile(x)\n",
    "        zip.extractall(unzip_file_path)\n",
    "        zip.close()\n",
    "        os.remove(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68383b58",
   "metadata": {},
   "source": [
    "# 02 - Etapa de Renomeação dos Arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121af243",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nome_arquivo in os.listdir(fr\"C:\\Temp\\Iesus\\dados\\arquivo_csv\"):\n",
    "    \n",
    "    nome_sem_extensao, _ = os.path.splitext(nome_arquivo)    \n",
    "    \n",
    "    nome_arquivo = fr\"C:\\Temp\\Iesus\\dados\\arquivo_csv\" + '\\\\' +nome_arquivo\n",
    "    novo_nome = fr\"C:\\Temp\\Iesus\\dados\\arquivo_csv\" + '\\\\' +nome_sem_extensao + \".CSV\"\n",
    "    os.rename(nome_arquivo, novo_nome)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8392d",
   "metadata": {},
   "source": [
    "# 03 - Etapa de Ingestão dos Arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e436a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNPJSchema = StructType([\n",
    "    StructField(\"CNPJ\", StringType(), True),\n",
    "    StructField(\"RAZAO_SOCIAL\", StringType(), True),\n",
    "    StructField(\"NATUREZA_JURIDICA\", StringType(), True),\n",
    "    StructField(\"QUALIFICACAO_RESPONSAVEL\", StringType(), True),\n",
    "    StructField(\"CAPITAL_SOCIAL\", DecimalType(), True),\n",
    "    StructField(\"PORTE_EMPRESA\", StringType(), True),\n",
    "    StructField(\"ENTE_FEDERATIVO\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_CNPJ = (spark.read.options(header='False'\n",
    "                            ,delimiter=';'\n",
    "                                    ,inferSchema='True'\n",
    "                                    )\n",
    "                                    .schema(CNPJSchema)\n",
    "                                    .csv(fr'C:\\Temp\\Iesus\\dados\\arquivo_csv\\*.CSV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebdfde72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|   total|\n",
      "+--------+\n",
      "|56195990|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT COUNT(1) total FROM {df}\"\"\", df=df_CNPJ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4eb21",
   "metadata": {},
   "source": [
    "# 04 - Etapa de Persistência do DataFrame em Parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3d0a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_do_diretorio = \"C:\\Temp\\Iesus\\dados\\parquet\"\n",
    "\n",
    "if os.path.exists(caminho_do_diretorio):\n",
    "    \n",
    "    if not os.listdir(caminho_do_diretorio):\n",
    "        \n",
    "        os.rmdir(caminho_do_diretorio)        \n",
    "        \n",
    "    else:\n",
    "\n",
    "        for arquivo in os.listdir(caminho_do_diretorio):\n",
    "                \n",
    "            arquivo_excluir = caminho_do_diretorio + '\\\\' + arquivo\n",
    "            os.remove(arquivo_excluir)\n",
    "            \n",
    "        os.rmdir(caminho_do_diretorio)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4667ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_CNPJ.coalesce(1).write.parquet(\"C:\\Temp\\Iesus\\dados\\parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9dd43",
   "metadata": {},
   "source": [
    "# 04.1 - Etapa de Importação do Arquivo no Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "041398ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_pandas = pd.read_parquet(\"C:\\Temp\\Iesus\\dados\\parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5a8dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56195990 entries, 0 to 56195989\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Dtype \n",
      "---  ------                    ----- \n",
      " 0   CNPJ                      object\n",
      " 1   RAZAO_SOCIAL              object\n",
      " 2   NATUREZA_JURIDICA         object\n",
      " 3   QUALIFICACAO_RESPONSAVEL  object\n",
      " 4   CAPITAL_SOCIAL            object\n",
      " 5   PORTE_EMPRESA             object\n",
      " 6   ENTE_FEDERATIVO           object\n",
      "dtypes: object(7)\n",
      "memory usage: 2.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_pandas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf06db1",
   "metadata": {},
   "source": [
    "# 04.2 - Etapa de Salvar os Dados em um Arquivo CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b50719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.to_csv(fr\"C:\\Temp\\Iesus\\dados\\arquivo_final\\arquivo_completo_parquet_cnpj.csv\"\n",
    "                 , sep=';'\n",
    "                 , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7df9c2",
   "metadata": {},
   "source": [
    "# 05 - Etapa de Persistência do DataFrame em CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0b3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_do_diretorio = \"C:\\Temp\\Iesus\\dados\\csv\"\n",
    "\n",
    "if os.path.exists(caminho_do_diretorio):\n",
    "    \n",
    "    if not os.listdir(caminho_do_diretorio):\n",
    "        \n",
    "        os.rmdir(caminho_do_diretorio)        \n",
    "        \n",
    "    else:\n",
    "\n",
    "        for arquivo in os.listdir(caminho_do_diretorio):\n",
    "                \n",
    "            arquivo_excluir = caminho_do_diretorio + '\\\\' + arquivo\n",
    "            os.remove(arquivo_excluir)\n",
    "            \n",
    "        os.rmdir(caminho_do_diretorio)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CNPJ.coalesce(1).write.format('com.databricks.spark.csv').save('C:\\Temp\\Iesus\\dados\\csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nome_arquivo in os.listdir(fr\"C:\\Temp\\Iesus\\dados\\csv\"):\n",
    "    \n",
    "    if nome_arquivo.endswith(\"csv\"):\n",
    "        \n",
    "        print(nome_arquivo)\n",
    "    \n",
    "        nome_sem_extensao, _ = os.path.splitext(nome_arquivo)    \n",
    "\n",
    "        nome_arquivo = fr\"C:\\Temp\\Iesus\\dados\\csv\" + '\\\\' +nome_arquivo\n",
    "        novo_nome = fr\"C:\\Temp\\Iesus\\dados\\arquivo_final\" + '\\\\arquivo_completo_parquet_cnpj.csv'\n",
    "        os.rename(nome_arquivo, novo_nome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
